# Stochastic-gradient-descent-learning-from-scratch
The objective is to code the stochastic gradient descent from scratch in order to train a feedforward NN

How to use it:
use the file SGD and create an object NN (neural network) with the size you want
then train it using NN.training like in the example

Ameliorations for the future: right now the cost function is 1/2*(a-y)**2, which is very convinient for calculation but not always the best cost function. In the future I will try to implement other cost functions such as cross-entropy.


